<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Veille technologique IA - Juin 2025 | Romain Begot</title>
  <meta name="description" content="Mise à jour Juin 2025 : actualités IA pour Anthropic, Google DeepMind et OpenAI. Perspectives 2025-2027."
  <meta name="keywords" content="veille IA, Anthropic, Google DeepMind, OpenAI, Claude, Gemini, GPT-5, Juin 2025">
  <meta name="author" content="Romain Begot">
  
  <!-- Open Graph -->
  <meta property="og:title" content="Veille technologique IA - Juin 2025">
  <meta property="og:description" content="Actualités IA Anthropic, Google/DeepMind et OpenAI. Perspectives 2025-2027">
  <meta property="og:type" content="website">
  <meta property="og:locale" content="fr_FR">
  
  <link rel="stylesheet" href="css/style.css">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9796611849898674" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Loader initial -->
  <div id="page-loader">
    <div class="loader-logo">
      <img src="img/22 mai 2025, 13_51_32.png" alt="Logo Romain Begot - Portfolio Professionnel" class="loader-img">
      <div class="loader-cyber"></div>
    </div>
    <div class="loader-text">Chargement du Portfolio...</div>
  </div>

  <header>
    <div class="navbar">
      <div class="navbar-left">
        <a href="index.html" class="navbar-logo">
          <img src="img/22 mai 2025, 13_51_32.png" alt="Logo Romain Begot - Retour à l'accueil">
        </a>
        <div class="site-title">Portfolio Romain Begot</div>
      </div>

      <button class="hamburger-menu" aria-label="Ouvrir le menu de navigation">
        <span class="hamburger-line"></span>
        <span class="hamburger-line"></span>
        <span class="hamburger-line"></span>
      </button>

      <nav class="main-nav">
        <ul class="menu">
          <li><a href="index.html">Accueil</a></li>
          <li><a href="mon-cv.html">Mon CV</a></li>
          <li><a href="ateliers.html">Mes AP</a></li>
          <li><a href="veille-tech.html" class="active">Veille Tech</a></li>
          <li class="submenu">
            <a href="stages.html" aria-haspopup="true" aria-expanded="false">Missions de Stage</a>
            <ul class="submenu-list">
              <li><a href="stages.html#mission-https-apache">Passage HTTPS Apache</a></li>
              <li><a href="missions-veeam-backup.html">Sauvegarde Veeam – relance en échec</a></li>
              </ul>
          </li>
        </ul>
      </nav>
    </div>
  </header>

<main>
<section id="veille-ia" class="container mx-auto px-4 py-10 text-slate-100 space-y-16">
  <h1 class="text-center text-4xl font-bold mb-8 gradient-text">Veille technologique — IA (mise à jour : Juin 2025)</h1>

  <!-- ================= ANTHROPIC ================= -->
  <article id="anthropic" class="space-y-6">
    <h2 class="text-3xl font-semibold border-b border-cyan-400 pb-2">Anthropic • Claude & Sonnet</h2>
    <ul class="list-disc list-inside space-y-3">
      <li><strong>Claude 3.7 Sonnet</strong> devient disponible sur tous les forfaits (Free, Pro, Team, Enterprise) et sur les API Bedrock & Vertex AI. </li>
      <li>Le modèle intègre un <em>Extended Thinking Mode</em> permettant des chaînes de raisonnement affichées à l’utilisateur. </li>
      <li><strong>Claude 4 (Opus 4 & Sonnet 4)</strong> est lancé en mai 2025 : +35 % de précision moyenne et contexte 256 k. </li>
      <li>Opus 4 domine le benchmark <em>SWE‑bench Verified</em> pour les tâches logicielles réelles. </li>
      <li>Recherche : cartographie de millions de « neurones » dans Claude — percée d’interprétabilité. </li>
      <li>Fortune salue une « ouverture de la boîte noire » après la découverte de circuits sémantiques. </li>
      <li>Série F : levée de <strong>3,5 G$</strong> (mars 2025) valorisant Anthropic 61,5 G$. </li>
      <li>Dette convertible : <strong>2,5 G$</strong> supplémentaires auprès des grandes banques (17 mai 2025). </li>
      <li>AWS injecte <strong>4 G$</strong> et collabore sur les puces Trainium 2 dans Bedrock. </li>
      <li>Claude 3.7 est désormais hébergé dans la région EU (Londres) sur Bedrock. </li>
      <li>Certification <strong>FedRAMP High & DoD IL4/5</strong> obtenue pour les charges sensibles US Gov. </li>
      <li>Partenariat pluriannuel avec <strong>Databricks</strong> pour outiller 10 000+ clients en agents Claude. </li>
      <li>Score de conformité 0,89 au nouvel <strong>EU AI Act Checker</strong>, devant Meta & OpenAI. </li>
      <li>L’Assemblée européenne expérimente Claude comme archiviste numérique, avec résultats mitigés. </li>
      <li>Anthropic rejoint le programme <strong>SAP × AWS AI Co‑Innovation</strong> pour ERP génératif. </li>
      <li>Tutoriels Bedrock : `Converse` API multi‑langages pour invoquer Claude depuis .NET → Swift. </li>
      <li>Blog AWS : « Claude Code » + prompt‑caching = latence réduite 40 %. </li>
      <li>Chris Olah (co‑fondateur) publie un plan de détection automatique des circuits de biais. </li>
      <li>Dario Amodei prédit l’ère du « milliardaire solo » grâce à l’IA d’ici 2026. </li>
      <li>Feuille de route : Amodei vise un <strong>Claude 5</strong> « quasi‑humain » à horizon 2027. </li>
    </ul>
    <h3 class="text-2xl mt-8 font-semibold">Perspectives 2025‑2027</h3>
    <p>Anthropic travaille sur <strong>Claude 5</strong> (contexte 1 M tokens et interprétabilité neuronale), l’intégration native dans Bedrock <em>Agents for SAP</em> et une empreinte carbone divisée par 3 via Trainium 2. </p>
  </article>

  <!-- ================= GOOGLE / DEEPMIND ================= -->
  <article id="google" class="space-y-6">
    <h2 class="text-3xl font-semibold border-b border-cyan-400 pb-2">Google / DeepMind • Gemini, Veo & Gemma</h2>
    <ul class="list-disc list-inside space-y-3">
      <li><strong>Gemini 2.5 Pro & Flash</strong> passent GA : audio natif, garde‑fous avancés, Project Mariner. </li>
      <li>Mode expérimental <em>Deep Think</em> booste la résolution de maths & code complexes. </li>
      <li><code>gemini-2.5-flash</code> GA le 17 juin 2025 (Vertex AI), cycle de vie publié. </li>
      <li><strong>AI Mode</strong> de Google Search déploie un Gemini 2.5 custom dans les Overviews US. </li>
      <li><strong>Gemini Live</strong> sur mobile gagne caméra + partage d’écran pour aide visuelle temps‑réel. </li>
      <li>Prototype multimodal <strong>Project Astra</strong> : assistant universel vers lunettes & Gemini Live. </li>
      <li><strong>Project Mariner</strong> (agent bureautique) accessible via Gemini API Ultra. </li>
      <li><strong>Gemini Robotics On‑Device</strong> offre autonomie hors‑ligne aux robots – VLA compact. </li>
      <li>Blog AI : Gemini 2.5 pour robotique & embodied intelligence (24 juin 2025). </li>
      <li>TechCrunch : modèle Gemini on‑device pour robots sans cloud. </li>
      <li><strong>AI Overviews</strong> déjà disponibles pour 200 M+ utilisateurs US, déploiement mondial prévu. </li>
      <li><strong>Veo 3</strong> s’intègre à YouTube Shorts (200 Md vues/j) dès cet été. </li>
      <li>Canva adopte aussi Veo 3 pour la génération vidéo créative. </li>
      <li>Veo 3 améliore la qualité vidéo et l’audio génératif. </li>
      <li>Famille <strong>Gemma</strong> : modèles open‑source légers issus de la recherche Gemini. </li>
      <li><strong>Gemma 3</strong> gère texte, images & vidéo sur 1 GPU, surpassant Llama 3 (Verge). </li>
      <li>Gemini API propose plusieurs variantes (Ultra, Pro, Flash, Flash‑Lite). </li>
      <li>SDK développeurs pour Robotics On‑Device ouvert aux « trusted testers ». </li>
      <li>Vision officielle : bâtir un assistant universel multimodal (blog DeepMind). </li>
      <li>Programme GSoC 2025 : évalue Gemini 2.5 & Gemma via benchmarks open‑source. </li>
    </ul>
    <h3 class="text-2xl mt-8 font-semibold">Perspectives 2025‑2027</h3>
    <p>Google prépare <strong>Gemini 3 Ultra</strong> (100 k tokens audio + vidéo 4K), <em>Veo 4</em> pour longs‑métrages et <strong>Gemma 4</strong> capable de fine‑tuning local sur TPU‑laptop. Un SDK <em>Agent Weaver</em> combinera Astra, Mariner et Gemini Live pour des agents multimodaux embarqués.</p>
  </article>

  <!-- ================= OPENAI ================= -->
  <article id="openai" class="space-y-6">
    <h2 class="text-3xl font-semibold border-b border-cyan-400 pb-2">OpenAI • ChatGPT, Sora, Codex & Stargate</h2>
    <ul class="list-disc list-inside space-y-3">
      <li>Lancement du modèle <strong>o3‑pro</strong> (10 juin 2025) pour les abonnés Pro + API. </li>
      <li>Mise à jour <em>Advanced Voice Mode</em> : intonation plus naturelle (7 juin 2025). </li>
      <li>TechCrunch détaille cadence réaliste et pauses expressives. </li>
      <li><strong>Sora</strong> génère vidéos réalistes & simulateur de monde — base pour agents physiques. </li>
      <li><strong>Codex</strong> ouvre l’accès Internet et arrive pour les abonnés ChatGPT Plus (3 juin 2025). </li>
      <li>Sam Altman confirme que <strong>GPT‑5</strong> sortira « probablement cet été ». </li>
      <li>Roadmap GPT‑5 : raisonnement amélioré & unification systèmes (Fello AI). </li>
      <li>Podcast OpenAI #1 : Altman détaille AGI et Project Stargate. </li>
      <li>Project Stargate : plan <strong>500 G$</strong> pour des data centers IA géants USA. </li>
      <li>Premier campus Abilene (TX) : 1,2 GW, 64 000 GB200 GPUs dès 2026. </li>
      <li>TechRepublic résume 10 faits clés sur le data center Stargate phase 1. </li>
      <li>Oracle investit 40 G$ en puces Nvidia pour Stargate — contrat 15 ans. </li>
      <li>OpenAI compte désormais <strong>3 M</strong> entreprises clientes (+1 M depuis février). </li>
      <li>Partenariat <strong>Apple Intelligence</strong> : modèles GPT embarqués sur iOS 26. </li>
      <li>Accord Jony Ive suspendu suite à litige de marque « io ». </li>
      <li>Rivalité croissante avec Microsoft Copilot selon Bloomberg. </li>
      <li>EU AI Act Checker pointe des failles de conformité dans GPT‑4o. </li>
      <li>Altman blog : énergie & intelligence bientôt « bon marché et quasi‑infinies ». </li>
      <li>YouTube rapport : GPT‑5 présenté comme « transformationnel ». </li>
      <li>Microsoft Build 2025 : Snowflake Summit — Altman évoque agents autonomes. </li>
    </ul>
    <h3 class="text-2xl mt-8 font-semibold">Perspectives 2025‑2027</h3>
    <p>OpenAI prévoit <strong>GPT‑5 public</strong> (été 2025) puis <strong>GPT‑o4‑full</strong> multimodal fin 2026, l’intégration de Sora dans la suite Adobe, et l’expansion mondiale de Stargate (Hub EMEA prévu à Abu Dhabi). OpenAI mise sur un coût GPU divisé par 2 grâce aux puces Blackwell GB200.</p>
  </article>
</section>
</main>

 <footer>
   <p>&copy; 2025 Romain Begot – Portfolio Professionnel | BTS SIO SISR | Veille Technologique IT & IA</p>
 </footer>

 <script src="js/loader.js"></script>
</body>
</html>