<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Veille technologique IA - Juin 2025 | Romain Begot</title>
  <meta name="description" content="Mise à jour Juin 2025 : actualités IA pour Anthropic, Google DeepMind et OpenAI. Perspectives 2025-2027."
  <meta name="keywords" content="veille IA, Anthropic, Google DeepMind, OpenAI, Claude, Gemini, GPT-5, Juin 2025">
  <meta name="author" content="Romain Begot">
  
  <!-- Open Graph -->
  <meta property="og:title" content="Veille technologique IA - Juin 2025">
  <meta property="og:description" content="Actualités IA Anthropic, Google/DeepMind et OpenAI. Perspectives 2025-2027">
  <meta property="og:type" content="website">
  <meta property="og:locale" content="fr_FR">
  
  <link rel="stylesheet" href="css/style.css">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9796611849898674" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Loader initial -->
  <div id="page-loader">
    <div class="loader-logo">
      <img src="img/22 mai 2025, 13_51_32.png" alt="Logo Romain Begot - Portfolio Professionnel" class="loader-img">
      <div class="loader-cyber"></div>
    </div>
    <div class="loader-text">Chargement du Portfolio...</div>
  </div>

  <header>
    <div class="navbar">
      <div class="navbar-left">
        <a href="index.html" class="navbar-logo">
          <img src="img/22 mai 2025, 13_51_32.png" alt="Logo Romain Begot - Retour à l'accueil">
        </a>
        <div class="site-title">Portfolio Romain Begot</div>
      </div>

      <button class="hamburger-menu" aria-label="Ouvrir le menu de navigation">
        <span class="hamburger-line"></span>
        <span class="hamburger-line"></span>
        <span class="hamburger-line"></span>
      </button>

      <nav class="main-nav">
        <ul class="menu">
          <li><a href="index.html">Accueil</a></li>
          <li><a href="mon-cv.html">Mon CV</a></li>
          <li><a href="ateliers.html">Mes AP</a></li>
          <li><a href="veille-tech.html" class="active">Veille Tech</a></li>
          <li class="submenu">
            <a href="stages.html" aria-haspopup="true" aria-expanded="false">Missions de Stage</a>
            <ul class="submenu-list">
              <li><a href="stages.html#mission-https-apache">Passage HTTPS Apache</a></li>
              <li><a href="missions-veeam-backup.html">Sauvegarde Veeam – relance en échec</a></li>
              </ul>
          </li>
        </ul>
      </nav>
    </div>
  </header>

<main>
<article class="veille-ia">
  <section class="veille">
    <h1 id="veille-tech">Veille technologique – IA (Mise à jour : juin 2025)</h1>

    <nav class="toc">
      <ul>
        <li><a href="#anthropic">Anthropic</a></li>
        <li><a href="#google-deepmind">Google / DeepMind</a></li>
        <li><a href="#openai">OpenAI</a></li>
        <li><a href="#perspectives">Perspectives 2025-2026</a></li>
        <li><a href="#references">Références</a></li>
      </ul>
    </nav>

    <section id="anthropic">
      <h2>Anthropic</h2>
      <h3>20 faits clés</h3>
      <ol>
        <li>21 juin 2024 – Lancement de Claude 3.5 Sonnet, modèle milieu de gamme plus rapide et moins coûteux que Claude 3 Sonnet.</li>
        <li>24 février 2025 – Présentation de Claude 3.7 Sonnet, premier modèle « hybrid reasoning » combinant réponses instantanées et raisonnement pas-à-pas.</li>
        <li>24 février 2025 – Dévoilement de Claude Code et de la variante Claude Sonnet 4, qui progresse en génération de code et en compréhension multimodale.</li>
        <li>12 mars 2025 – Intégration de Claude 3.7 Sonnet dans Amazon Bedrock Knowledge Bases.</li>
        <li>Mai 2025 – Activation du “prompt caching” sur Bedrock pour Sonnet 4, divisant la latence par deux.</li>
        <li>22 mai 2025 – Annonce officielle de la famille Claude 4 (Opus 4, Sonnet 4) : 200 k tokens de contexte et agents d’orchestration intégrés.</li>
        <li>Juin 2025 – Pré-annonce d’une gamme Claude 4 optimisée pour les workflows d’agents complexes.</li>
        <li>23 juin 2025 – Mise en production du profil d’inférence « Claude 3.5 Sonnet v2 » pour un routage plus efficace.</li>
        <li>Investissement stratégique dans la start-up Goodfire, spécialisée en interprétabilité.</li>
        <li>Feuille de route 2027 : cartographie des circuits internes pour rendre Claude totalement interprétable.</li>
        <li>Lancement d’outils « extended thinking » permettant d’exposer le raisonnement détaillé via l’API.</li>
        <li>Partenariat élargi avec AWS : disponibilité de Claude dans dix régions, dont Paris (eu-west-3).</li>
        <li>Profils d’inférence régionaux garantissant la souveraineté des données clients européens.</li>
        <li>Ajout d’un plug-in VS Code fournissant complétions et refactorings contextuels (“Claude Code”).</li>
        <li>Claude 3 Haiku reste la variante la plus rapide (≈ 21 k tokens/s) pour les prompts ≤ 32 k tokens.</li>
        <li>Arrivée de Mike Krieger (co-fondateur d’Instagram) au poste de Chief Product Officer.</li>
        <li>Levée de fonds de 3,5 G$ portant la valorisation à plus de 60 G$ et prévoyant 100 embauches en Europe.</li>
        <li>Déploiement de “Claude Robotics” pour des agents de pricing chez Amazon Bedrock.</li>
        <li>Nouvelle API « extended thinking tips » suggérant des stratégies avancées de prompt engineering.</li>
        <li>Dario Amodei estime plausible l’émergence d’une IA super-intelligente dès 2026.</li>
      </ol>
      <p>Claude 3.5 puis 3.7 ont placé Anthropic sur le terrain du raisonnement explicite. Avec Claude 4, la société poursuit un double objectif : fenêtre de contexte record et agents autonomes fiables. La stratégie s’appuie sur des partenariats cloud (AWS) et une R&D forte en interprétabilité, soutenue par de nouveaux financements et talents clés.</p>
    </section>

    <section id="google-deepmind">
      <h2>Google / DeepMind</h2>
      <h3>20 faits clés</h3>
      <ol>
        <li>17 juin 2025 – Passage en GA de Gemini 2.5 Pro sur Vertex AI.</li>
        <li>17 juin 2025 – Sortie de Gemini 2.5 Flash, variante rapide à faible coût.</li>
        <li>Fin mai 2025 – Déploiement de Gemini 2.5 Pro Preview dans l’application Gemini (web / mobile).</li>
        <li>Nouvelle grille tarifaire : Gratuit, AI Pro (19,99 $/mois, 2 To), AI Ultra (249,99 $/mois).</li>
        <li>Veo 3, modèle vidéo + audio natifs, génère des clips 1080 p de 8 s.</li>
        <li>Veo 3 intégré au flux YouTube Shorts (lancement prévu durant l’été 2025).</li>
        <li>Veo 3 disponible dans Canva via la fonctionnalité “Create a Video Clip”.</li>
        <li>DeepMind publie Gemini Robotics on-device pour robots autonomes.</li>
        <li>SDK Gemini Robotics ouvert aux testeurs pour faciliter le fine-tuning.</li>
        <li>Blog développeurs : migration obligatoire des chaînes modèle 2.5 Preview → 2.5 Pro avant le 19 juin 2025.</li>
        <li>Gemma 2 (9 B, 27 B) dépasse Llama 3 8 B sur Arena et s’optimise pour CPU/GPU locaux.</li>
        <li>Version quantisée de Gemma 2 fonctionnant sur laptop sans GPU dédié.</li>
        <li>7 juillet 2025 – Gemini gagne le contrôle avancé des applications sur Android.</li>
        <li>I/O 2025 : Veo 3 accessible aux abonnés AI Ultra US et via Vertex AI.</li>
        <li>Google Cloud Next 2025 : Agent Development Kit (ADK) open-source pour créer des agents multi-fournisseurs.</li>
        <li>Gemini Robotics hybride cloud / on-device conserve une option de routage sécurisé.</li>
        <li>Chromebooks Plus embarquent Gemini pour “Live Translate” et “Help Me Read”.</li>
        <li>Google finance 10 000 $ de crédits Cloud aux chercheurs utilisant Gemma 3.</li>
        <li>Gemma 3 ambitionne d’être le meilleur modèle 1-GPU avec vision haute résolution.</li>
        <li>Flood Hub enrichi par Gemini pour la prévision des crues sur 80 pays.</li>
      </ol>
      <p>Google poursuit une stratégie multi-modèles (Gemini, Gemma, Veo) visant à couvrir cloud, on-device et multimédia. L’intégration serrée dans Android, YouTube, Canva et Vertex AI traduit une volonté d’ancrage produit, tandis que l’ADK ouvre la voie à un écosystème d’agents interopérables.</p>
    </section>

    <section id="openai">
      <h2>OpenAI</h2>
      <h3>20 faits clés</h3>
      <ol>
        <li>30 avril 2025 – GPT-4 retiré de ChatGPT, remplacé par GPT-4o par défaut.</li>
        <li>Juillet 2024 – GPT-4o mini succède à GPT-3.5 Turbo.</li>
        <li>GPT-4o déployable sur Azure AI Foundry (modèles 2024-11-20).</li>
        <li>7 juin 2025 – Amélioration majeure du Voice Mode (intonation, fluidité, traduction temps réel).</li>
        <li>Déploiement progressif du Voice Mode confirmé sur desktop, mobile et web.</li>
        <li>GPT-4.1 API remplace GPT-4.5 Preview (retrait prévu le 14 juillet 2025).</li>
        <li>3 juin 2025 – Codex avec accès Internet ouvert aux abonnés Plus.</li>
        <li>6 juin 2025 – SD Times détaille l’automatisation des builds via Codex.</li>
        <li>Sora permet la génération vidéo 1080 p de 20 s via interface web.</li>
        <li>Aucun API public Sora annoncé pour l’instant.</li>
        <li>Sam Altman annonce GPT-5 pour l’été 2025.</li>
        <li>Plusieurs indices de release GPT-5 repérés dans les communications publiques.</li>
        <li>OpenAI publie un rapport (juin 2025) sur la lutte contre les usages malveillants de l’IA.</li>
        <li>Voice Mode utilise GPT-4o pour transcription et synthèse.</li>
        <li>GPT-4o remplace DALL-E 3 pour la génération d’images depuis mars 2025.</li>
        <li>GPT-4o mini réduit le coût des tokens de plus de 60 %.</li>
        <li>Azure met à jour automatiquement gpt-35-turbo vers la version 0125 (janv. 2025).</li>
        <li>OpenAI envisage une monétisation par publicités dans ChatGPT.</li>
        <li>Sora supporte les ratios 9:16, 1:1 et 16:9.</li>
        <li>Codex peut installer dépendances, exécuter tests et mettre à jour le code dans un sandbox sécurisé.</li>
      </ol>
      <p>OpenAI accélère la cadence : GPT-4o devient le nouveau standard, complété par une gamme mini, une expérience voix enrichie et l’arrivée de Sora pour la vidéo. Tout converge vers GPT-5 et l’extension agentique, tout en renforçant la distribution via Azure et un modèle économique élargi.</p>
    </section>

    <section id="perspectives">
      <h2>Perspectives 2025-2026</h2>
      <ul>
        <li><strong>Anthropic :</strong> Claude 5 visera une gouvernance d’outils externe, un monitoring explicable en production et la collaboration prolongée entre agents.</li>
        <li><strong>Google / DeepMind :</strong> Gemini 3 (> 30 T paramètres) cherchera à unifier modalité et agenticité tandis que l’ADK devrait structurer un écosystème d’agents tiers.</li>
        <li><strong>OpenAI :</strong> GPT-5 promet un saut de capacités et pourrait inaugurer une API Sora si les risques de génération vidéo sont maîtrisés ; l’assistant se rapprochera d’un agent complet.</li>
      </ul>
    </section>

    <section id="references">
      <h2>Références</h2>
      <ol>
        <li>Anthropic – Claude 3.5 Sonnet (21 juin 2024)</li>
        <li>Anthropic – Claude 3.7 Sonnet (24 févr. 2025)</li>
        <li>Anthropic – Claude 4 (22 mai 2025)</li>
        <li>Google Cloud – Gemini 2.5 Pro GA (17 juin 2025)</li>
        <li>Canva Newsroom – Veo 3 dans Canva (juin 2025)</li>
        <li>The Verge – Veo 3 dans YouTube Shorts (juin 2025)</li>
        <li>OpenAI – ChatGPT Release Notes (30 avr. 2025)</li>
        <li>DataStudios – Voice Mode Upgrade (juin 2025)</li>
        <li>OpenAI – Sora is here (janv. 2025)</li>
        <li>Adweek – Sam Altman annonce GPT-5 (juin 2025)</li>
        <li>Google Developers Blog – Gemma 2 release</li>
        <li>Times of India – Veo 3 Canva integration</li>
        <li>Microsoft Learn – GPT-4o model names (nov. 2024)</li>
        <li>ArsTechnica – GPT-4o mini launch (juil. 2024)</li>
        <li>Reuters – GPT-4o mini pricing</li>
      </ol>
    </section>
</article>
  </section>
</main>

 <footer>
   <p>&copy; 2025 Romain Begot – Portfolio Professionnel | BTS SIO SISR | Veille Technologique IT & IA</p>
 </footer>

 <script src="js/loader.js"></script>
</body>
</html>