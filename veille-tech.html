<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Veille technologique IA - Juin 2025 | Romain Begot</title>
  <meta name="description" content="Mise à jour Juin 2025 : actualités IA pour Anthropic, Google DeepMind et OpenAI. Perspectives 2025-2027."
  <meta name="keywords" content="veille IA, Anthropic, Google DeepMind, OpenAI, Claude, Gemini, GPT-5, Juin 2025">
  <meta name="author" content="Romain Begot">
  
  <!-- Open Graph -->
  <meta property="og:title" content="Veille technologique IA - Juin 2025">
  <meta property="og:description" content="Actualités IA Anthropic, Google/DeepMind et OpenAI. Perspectives 2025-2027">
  <meta property="og:type" content="website">
  <meta property="og:locale" content="fr_FR">
  
  <link rel="stylesheet" href="css/style.css">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9796611849898674" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Loader initial -->
  <div id="page-loader">
    <div class="loader-logo">
      <img src="img/22 mai 2025, 13_51_32.png" alt="Logo Romain Begot - Portfolio Professionnel" class="loader-img">
      <div class="loader-cyber"></div>
    </div>
    <div class="loader-text">Chargement du Portfolio...</div>
  </div>

  <header>
    <div class="navbar">
      <div class="navbar-left">
        <a href="index.html" class="navbar-logo">
          <img src="img/22 mai 2025, 13_51_32.png" alt="Logo Romain Begot - Retour à l'accueil">
        </a>
        <div class="site-title">Portfolio Romain Begot</div>
      </div>

      <button class="hamburger-menu" aria-label="Ouvrir le menu de navigation">
        <span class="hamburger-line"></span>
        <span class="hamburger-line"></span>
        <span class="hamburger-line"></span>
      </button>

      <nav class="main-nav">
        <ul class="menu">
          <li><a href="index.html">Accueil</a></li>
          <li><a href="mon-cv.html">Mon CV</a></li>
          <li><a href="ateliers.html">Mes AP</a></li>
          <li><a href="veille-tech.html" class="active">Veille Tech</a></li>
          <li class="submenu">
            <a href="stages.html" aria-haspopup="true" aria-expanded="false">Missions de Stage</a>
            <ul class="submenu-list">
              <li><a href="stages.html#mission-https-apache">Passage HTTPS Apache</a></li>
              <li><a href="missions-veeam-backup.html">Sauvegarde Veeam – relance en échec</a></li>
              </ul>
          </li>
        </ul>
      </nav>
    </div>
  </header>

<main>
<article class="veille-ia">
  <h2>Veille IA – Juin 2025</h2>
  <p class="intro">Ce dossier rassemble les développements marquants des six derniers mois chez Anthropic, Google / DeepMind et OpenAI, ainsi que leurs perspectives à horizon 2026.</p>

  <h3>Anthropic : 20 faits clés</h3>
  <ul>
    <li><strong>21 juin 2024</strong> – Lancement de Claude 3.5 Sonnet, modèle milieu de gamme plus rapide et moins coûteux que Claude 3 Sonnet citeturn0search0.</li>
    <li><strong>24 févr. 2025</strong> – Dévoilement de Claude 3.7 Sonnet : premier modèle « hybrid reasoning » offrant réponse instantanée ou raisonnement pas-à-pas citeturn7search7.</li>
    <li><strong>24 févr. 2025</strong> – Sortie simultanée de Claude Sonnet 4, bond de performance en codage et compréhension citeturn0search3.</li>
    <li><strong>Juin 2025</strong> – Annonce de la famille Claude 4, optimisée pour workflows agents complexes citeturn0search9.</li>
    <li>La variante Claude Opus 4 atteint une fenêtre de contexte de <em>200 k tokens</em>, record du marché citeturn7search0.</li>
    <li>Objectif public : cartographier les circuits internes des modèles d’ici 2027 pour une IA interprétable citeturn1search1.</li>
    <li>Publication d’outils « extended thinking » pour exposer le raisonnement de Claude dans l’API citeturn7search4.</li>
    <li><strong>12 mars 2025</strong> – Claude 3.7 Sonnet intégré à Amazon Bedrock Knowledge Bases citeturn2search2.</li>
    <li><strong>Mai 2025</strong> – Bedrock active le <em>prompt caching</em> pour Sonnet 4, divisant la latence par 2 citeturn2search1.</li>
    <li><strong>23 juin 2025</strong> – Mise en production du profil d’inference Claude 3.5 Sonnet v2 pour routage optimisé citeturn2search4.</li>
    <li>Levée de fonds de 3,5 G$ portant la valorisation à > 60 G$ ; 100 embauches prévues en Europe citeturn1news38.</li>
    <li>Investissement stratégique dans la start-up Goodfire dédiée à l’interprétabilité citeturn1news38.</li>
    <li>Arrivée de Mike Krieger (Instagram) comme CPO pour accélérer les produits grand-public citeturn7news10.</li>
    <li>Claude Code fournit désormais complétions et refactorings contextuels dans VS Code citeturn7search7.</li>
    <li>Claude 3 Haiku reste la variante la plus rapide (21 k tokens/s) pour prompts ≤ 32 k citeturn7search6.</li>
    <li>Partenariat AWS : Claude disponible dans 10 régions via Bedrock, avec intégration Guardrails citeturn2search0.</li>
    <li>Nouvelle API « extended thinking tips » propose des stratégies de prompt engineering avancées citeturn7search1.</li>
    <li>Dario Amodei estime plausible l’émergence d’une IA super-intelligente dès 2026 citeturn1news38.</li>
    <li>Claude Robotics équipe des agents de pricing chez Amazon Bedrock citeturn2search3.</li>
    <li>Les profils d’inference régionaux garantissent la souveraineté des données clients (Paris eu-west-3) citeturn2search2.</li>
  </ul>

  <h3>Google / DeepMind : 20 faits clés</h3>
  <ul>
    <li><strong>17 juin 2025</strong> – GA de Gemini 2.5 Pro sur Vertex AI, avec meilleures performances de raisonnement citeturn3search0.</li>
    <li>Même jour : sortie de Gemini 2.5 Flash, variante rapide et peu coûteuse citeturn3search7.</li>
    <li>Le déploiement 2.5 Pro Preview sur l’appli Gemini web/mobile a démarré fin mai 2025 citeturn3search2.</li>
    <li>Nouveaux paliers tarifaires : Gratuit, AI Pro (19,99 $/mois, 2 To), AI Ultra (249,99 $/mois) citeturn3search6.</li>
    <li>Veo 3, modèle vidéo + audio natifs, génère des clips 8 s en 1080 p citeturn0search1.</li>
    <li>Veo 3 intégré au flux Shorts de YouTube et à l’appli Gemini citeturn0search7.</li>
    <li>DeepMind publie aujourd’hui une version Gemini Robotics <em>on-device</em> pour robots autonomes citeturn0news28turn3news24.</li>
    <li>SDK Gemini Robotics ouvert aux testeurs afin de faciliter le fine-tuning citeturn3news24.</li>
    <li>Blog développeurs : migration des chaînes modèle 2.5 Preview → 2.5 Pro avant le 19 juin 2025 citeturn3search4.</li>
    <li>Gemma 2 (9B, 27B) dépasse Llama 3 8B sur Arena, optimisée pour CPU/GPU locaux citeturn1search0.</li>
    <li>Gemma 2 quantisée fonctionne sur laptops sans GPU dédié citeturn1search0.</li>
    <li>Android : Gemini gagnera le contrôle avancé des apps dès le 7 juillet 2025 citeturn3search3.</li>
    <li>I/O 2025 : Veo 3 accessible aux abonnés AI Ultra US et via Vertex AI citeturn9search0.</li>
    <li>Google Cloud Next 2025 : Agent Development Kit (ADK) open-source pour construire des agents multi-fournisseurs citeturn9search2.</li>
    <li>Gemini Robotics modèle hybride cloud/on-device conserve option de routage sécurisé citeturn3news24.</li>
    <li>Chromebooks Plus embarquent Gemini pour Live Translate et Help Me Read citeturn9search4.</li>
    <li>Google finance 10 000 $ de crédits Cloud aux chercheurs utilisant Gemma 3 citeturn9news10.</li>
    <li>Gemma 3 se veut le plus puissant modèle 1 GPU avec vision haute résolution citeturn9news10.</li>
    <li>Gemini 2.5 Flash arrive bientôt dans Vertex AI pour latence ultra-basse citeturn9search2.</li>
    <li>Flood Hub enrichi par Gemini pour la prévision des crues sur 80 pays citeturn9search5.</li>
  </ul>

  <h3>OpenAI : 20 faits clés</h3>
  <ul>
    <li><strong>30 avr. 2025</strong> – GPT‐4 remplacé par GPT‐4o par défaut dans ChatGPT grand public citeturn4news28.</li>
    <li>GPT‐4o mini a succédé à GPT‐3.5 Turbo dès juillet 2024 citeturn8search4.</li>
    <li>GPT‐4o est déployable sur Azure AI Foundry (modèles 2024-11-20) citeturn4search0.</li>
    <li><strong>7 juin 2025</strong> – Amélioration majeure du Voice Mode (intonation, fluidité) pour abonnés Plus citeturn8search0.</li>
    <li>Voice Mode offre traduction multilingue temps réel et latence réduite citeturn8search2.</li>
    <li>Roll-out progressif de Voice Mode confirmé par la communauté développeurs citeturn8search3.</li>
    <li>GPT‐4.1 API remplace GPT‐4.5 Preview (retrait 14 juil. 2025) citeturn4search3.</li>
    <li><strong>3 juin 2025</strong> – Codex accessible à tous les abonnés Plus avec internet opt-in citeturn4search2.</li>
    <li>SD Times détaille l’ajout d’accès Internet et l’automatisation de builds le 6 juin 2025 citeturn4search8.</li>
    <li>Forum dev : Codex exécute installations, tests et upgrades dans le sandbox citeturn4search5.</li>
    <li>Sora permet la génération vidéo 20 sec 1080 p via interface web citeturn4search1.</li>
    <li>Aucun API public Sora n’est prévu à ce stade (AMA avril 2025) citeturn4search4.</li>
    <li>Sora supporte aspect ratios 9:16, 1:1, 16:9 citeturn4search1.</li>
    <li>OpenAI publie un rapport sur la lutte contre les usages malveillants de l’IA (juin 2025) citeturn1search6.</li>
    <li>Sam Altman annonce GPT‐5 pour l’été 2025, promettant bond de capacités citeturn0search5.</li>
    <li>ExplodingTopics recense indices de release GPT‐5 dans posts d’Altman citeturn0search8.</li>
    <li>Voice Mode repose sur GPT‐4o pour transcription et synthèse citeturn8search1.</li>
    <li>GPT‐4o a remplacé DALL‐E 3 pour l’image en mars 2025 citeturn8search4.</li>
    <li>Déploiement alpha de Voice Mode démarré en juillet 2024 auprès de quelques Plus users citeturn8search6.</li>
    <li>Azure auto-met à jour gpt-35-turbo vers version 0125 dès janv. 2025 citeturn4search6.</li>
  </ul>

  <h3>Perspectives 2025–26</h3>
  <p><strong>Anthropic</strong> vise Claude 5 doté d’une gouvernance d’outils externe et d’un monitoring explicable en production (objectif 2026) ; explore un modèle agent collaboratif capable d’« heures de travail » autonomes citeturn1search5.</p>
  <p><strong>Google / DeepMind</strong> travaille sur Gemini 3 (> 30 T params) pour IA multimodale unifiée et concentre la R&D sur l’agent framework ADK afin de créer un écosystème d’agents interopérables citeturn9news10turn9search2.</p>
  <p><strong>OpenAI</strong> prépare GPT‐5, censé unifier architecture « omni » et capacités agents ; Sora API reste en réflexion en fonction des risques génération vidéo citeturn0search5turn4search4.</p>
</article>
</main>

 <footer>
   <p>&copy; 2025 Romain Begot – Portfolio Professionnel | BTS SIO SISR | Veille Technologique IT & IA</p>
 </footer>

 <script src="js/loader.js"></script>
</body>
</html>